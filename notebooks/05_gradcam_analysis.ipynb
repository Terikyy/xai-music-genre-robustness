{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1d5ac2e",
   "metadata": {},
   "source": [
    "# Grad-CAM Analysis for Music Genre Classification\n",
    "\n",
    "This notebook performs explainability analysis using Grad-CAM (Gradient-weighted Class Activation Mapping) to understand:\n",
    "\n",
    "1. **Baseline (Correct Predictions)**: What frequency/time regions the model focuses on for correct classifications\n",
    "2. **Natural Failures**: Where the model looks when it makes mistakes (without adversarial attacks)\n",
    "3. **Adversarial Failures**: How model attention shifts after adversarial perturbations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be78cb02",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675b56cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Add src to path\n",
    "PROJECT_ROOT = Path('../').resolve()\n",
    "sys.path.insert(0, str(PROJECT_ROOT / 'src'))\n",
    "\n",
    "# Import custom modules\n",
    "from models.cnn import GenreClassifierCNN\n",
    "from attacks.adversarial import prepare_classifier, generate_fgsm_attack, generate_pgd_attack\n",
    "from explainability.gradcam import GradCAMExplainer, visualize_gradcam, compare_gradcam_side_by_side\n",
    "\n",
    "# Define paths\n",
    "DATA_PATH = PROJECT_ROOT / 'data'\n",
    "PROCESSED_PATH = DATA_PATH / 'processed'\n",
    "RESULTS_PATH = PROJECT_ROOT / 'results'\n",
    "MODEL_PATH = RESULTS_PATH / 'models'\n",
    "FIGURES_PATH = RESULTS_PATH / 'figures'\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf903262",
   "metadata": {},
   "source": [
    "## 2. Load Metadata and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df323f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "metadata_path = PROCESSED_PATH / 'metadata.json'\n",
    "with open(metadata_path, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "genre_to_id = metadata['genre_to_id']\n",
    "id_to_genre = {int(k): v for k, v in metadata['id_to_genre'].items()}\n",
    "genres = metadata['genres']\n",
    "\n",
    "print(f\"Number of classes: {metadata['n_classes']}\")\n",
    "print(f\"Genres: {genres}\")\n",
    "print(f\"Input shape: {metadata['input_shape']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5af296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "X_test = np.load(PROCESSED_PATH / 'test' / 'X.npy')\n",
    "y_test = np.load(PROCESSED_PATH / 'test' / 'y.npy')\n",
    "track_ids_test = np.load(PROCESSED_PATH / 'test' / 'track_ids.npy')\n",
    "\n",
    "print(f\"\\nTest set shape: {X_test.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")\n",
    "print(f\"Track IDs shape: {track_ids_test.shape}\")\n",
    "print(f\"Input range: [{X_test.min():.3f}, {X_test.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2bc110",
   "metadata": {},
   "source": [
    "## 3. Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a034138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "model = GenreClassifierCNN(num_classes=10)\n",
    "model.load_state_dict(torch.load(MODEL_PATH / 'genre_cnn_pytorch_best.pth', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "print(f\"Model architecture: {model.__class__.__name__}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba77b8e5",
   "metadata": {},
   "source": [
    "## 4. Get Model Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65df6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on test set\n",
    "X_test_tensor = torch.from_numpy(X_test).permute(0, 3, 1, 2).float().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(X_test_tensor)\n",
    "    predictions = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "    probabilities = F.softmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(f\"Test accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# Identify correct and incorrect predictions\n",
    "correct_mask = predictions == y_test\n",
    "incorrect_mask = ~correct_mask\n",
    "\n",
    "print(f\"\\nCorrect predictions: {correct_mask.sum()}/{len(y_test)}\")\n",
    "print(f\"Incorrect predictions: {incorrect_mask.sum()}/{len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9dbbe7",
   "metadata": {},
   "source": [
    "## 5. Initialize Grad-CAM Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9723952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Grad-CAM explainer with the last convolutional layer\n",
    "target_layer = model.get_last_conv_layer()\n",
    "explainer = GradCAMExplainer(model=model, target_layer=target_layer, device=device)\n",
    "\n",
    "print(f\"Grad-CAM explainer initialized\")\n",
    "print(f\"Target layer: {target_layer.__class__.__name__}\")\n",
    "print(f\"Target layer output channels: {target_layer.out_channels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9a0bf8",
   "metadata": {},
   "source": [
    "## 6. Baseline Analysis - Correct Predictions\n",
    "\n",
    "Select and analyze correctly classified samples to understand what frequency/time regions the model focuses on for correct decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762d8570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select diverse correctly classified samples (two high-confidence samples per genre)\n",
    "correct_indices = np.where(correct_mask)[0]\n",
    "correct_samples = []\n",
    "\n",
    "print(\"Selecting correctly classified samples (two per genre with highest confidence)...\")\n",
    "\n",
    "# Get two high-confidence correct predictions per genre\n",
    "for genre_id in range(10):\n",
    "    genre_correct = [i for i in correct_indices if y_test[i] == genre_id]\n",
    "    if genre_correct:\n",
    "        # Sort by confidence and take the top 2\n",
    "        confidences = [probabilities[i, genre_id] for i in genre_correct]\n",
    "        sorted_indices = sorted(zip(genre_correct, confidences), key=lambda x: x[1], reverse=True)\n",
    "        # Add top 2 samples for this genre\n",
    "        for idx, conf in sorted_indices[:2]:\n",
    "            correct_samples.append(idx)\n",
    "\n",
    "print(f\"\\nSelected {len(correct_samples)} correctly classified samples:\")\n",
    "for idx in correct_samples:\n",
    "    true_genre = id_to_genre[y_test[idx]]\n",
    "    pred_genre = id_to_genre[predictions[idx]]\n",
    "    conf = probabilities[idx, predictions[idx]]\n",
    "    print(f\"  Sample {idx}: {true_genre} (confidence: {conf:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa148c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Grad-CAM visualizations for correct predictions\n",
    "print(\"Generating Grad-CAM visualizations for correct predictions...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create subdirectory for baseline analysis\n",
    "baseline_path = FIGURES_PATH / 'gradcam' / 'baseline_correct'\n",
    "baseline_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i, idx in enumerate(correct_samples):\n",
    "    print(f\"\\nProcessing correct sample {i+1}/{len(correct_samples)}...\")\n",
    "    \n",
    "    # Get sample data\n",
    "    input_spec = X_test[idx]\n",
    "    true_label = y_test[idx]\n",
    "    \n",
    "    # Analyze with Grad-CAM\n",
    "    analysis = explainer.analyze_sample(\n",
    "        spectrogram=input_spec,\n",
    "        true_label=true_label,\n",
    "        label_names=id_to_genre,\n",
    "        get_prediction=True\n",
    "    )\n",
    "    \n",
    "    # Create visualization\n",
    "    title = f\"Correct Prediction - Sample {i+1}\"\n",
    "    save_path = baseline_path / f'correct_{i+1:02d}_{analysis[\"true_label_name\"]}.png'\n",
    "    \n",
    "    visualize_gradcam(\n",
    "        spectrogram=input_spec,\n",
    "        heatmap=analysis['heatmap'],\n",
    "        title=title,\n",
    "        prediction=analysis['predicted_label'],\n",
    "        true_label=analysis['true_label_name'],\n",
    "        confidence=analysis['confidence'],\n",
    "        save_path=str(save_path),\n",
    "        show_plot=True\n",
    "    )\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\n✓ Section 1 complete! Visualizations saved to {baseline_path}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743b7ef9",
   "metadata": {},
   "source": [
    "**Observations: Attention Patterns in Correct Predictions**\n",
    "\n",
    "- The model shows **genre-specific attention patterns** - different music genres activate different regions of the spectrograms\n",
    "- Attention patterns are **consistent within the same genre** across different samples, indicating reliable learned features\n",
    "- The model focuses on **localized regions** rather than the entire spectrogram uniformly\n",
    "- The **consistency across the two samples per genre** confirms stable decision-making strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d6b496",
   "metadata": {},
   "source": [
    "## 7. Natural Failures - Misclassifications Without Attacks\n",
    "\n",
    "Analyze naturally misclassified examples to understand where the model fails without adversarial perturbations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b2fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select diverse misclassified samples (5 high-confidence mistakes)\n",
    "incorrect_indices = np.where(incorrect_mask)[0]\n",
    "misclassified_samples = []\n",
    "comparison_correct_samples = []\n",
    "\n",
    "print(\"Selecting misclassified samples (5 high-confidence mistakes from different genres)...\")\n",
    "\n",
    "# Get diverse misclassifications - try one per true genre\n",
    "for genre_id in range(10):\n",
    "    genre_incorrect = [i for i in incorrect_indices if y_test[i] == genre_id]\n",
    "    if genre_incorrect:\n",
    "        # Sort by confidence in wrong prediction (most confident mistakes)\n",
    "        confidences = [probabilities[i, predictions[i]] for i in genre_incorrect]\n",
    "        if confidences:\n",
    "            best_idx = genre_incorrect[np.argmax(confidences)]\n",
    "            misclassified_samples.append(best_idx)\n",
    "\n",
    "# Take only the first 5 samples\n",
    "misclassified_samples = misclassified_samples[:5]\n",
    "\n",
    "# For each misclassification, find a correctly classified sample of the predicted genre\n",
    "print(\"\\nFinding correctly classified samples of the predicted genres for comparison...\")\n",
    "for idx in misclassified_samples:\n",
    "    predicted_genre_id = predictions[idx]\n",
    "    # Find correct predictions for this genre\n",
    "    genre_correct = [i for i in correct_indices if y_test[i] == predicted_genre_id]\n",
    "    if genre_correct:\n",
    "        # Take the highest confidence correct prediction\n",
    "        confidences = [probabilities[i, predicted_genre_id] for i in genre_correct]\n",
    "        best_correct_idx = genre_correct[np.argmax(confidences)]\n",
    "        comparison_correct_samples.append(best_correct_idx)\n",
    "    else:\n",
    "        comparison_correct_samples.append(None)\n",
    "\n",
    "print(f\"\\nSelected {len(misclassified_samples)} misclassified samples:\")\n",
    "for i, idx in enumerate(misclassified_samples):\n",
    "    true_genre = id_to_genre[y_test[idx]]\n",
    "    pred_genre = id_to_genre[predictions[idx]]\n",
    "    conf = probabilities[idx, predictions[idx]]\n",
    "    comp_idx = comparison_correct_samples[i]\n",
    "    comp_info = f\" | Comparison: sample {comp_idx}\" if comp_idx is not None else \" | No comparison available\"\n",
    "    print(f\"  Sample {idx}: True={true_genre}, Predicted={pred_genre} (confidence: {conf:.4f}){comp_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7e80bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Grad-CAM visualizations for misclassifications with comparisons\n",
    "print(\"\\nGenerating Grad-CAM visualizations for misclassifications...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create subdirectory for misclassification analysis\n",
    "misclass_path = FIGURES_PATH / 'gradcam' / 'natural_failures'\n",
    "misclass_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i, idx in enumerate(misclassified_samples):\n",
    "    print(f\"\\nProcessing misclassification {i+1}/{len(misclassified_samples)}...\")\n",
    "    \n",
    "    # Get misclassified sample data\n",
    "    input_spec = X_test[idx]\n",
    "    true_label = y_test[idx]\n",
    "    \n",
    "    # Analyze misclassified sample with Grad-CAM\n",
    "    analysis = explainer.analyze_sample(\n",
    "        spectrogram=input_spec,\n",
    "        true_label=true_label,\n",
    "        label_names=id_to_genre,\n",
    "        get_prediction=True\n",
    "    )\n",
    "    \n",
    "    # Create visualization for misclassified sample\n",
    "    title = f\"Misclassification - Sample {i+1}\"\n",
    "    save_path = misclass_path / f'misclass_{i+1:02d}_{analysis[\"true_label_name\"]}_as_{analysis[\"predicted_label\"]}.png'\n",
    "    \n",
    "    visualize_gradcam(\n",
    "        spectrogram=input_spec,\n",
    "        heatmap=analysis['heatmap'],\n",
    "        title=title,\n",
    "        prediction=analysis['predicted_label'],\n",
    "        true_label=analysis['true_label_name'],\n",
    "        confidence=analysis['confidence'],\n",
    "        save_path=str(save_path),\n",
    "        show_plot=True\n",
    "    )\n",
    "    \n",
    "    # Generate comparison with correctly classified sample of the predicted genre\n",
    "    comp_idx = comparison_correct_samples[i]\n",
    "    if comp_idx is not None:\n",
    "        print(f\"  Generating comparison with correctly classified {id_to_genre[predictions[idx]]} sample...\")\n",
    "        \n",
    "        comp_spec = X_test[comp_idx]\n",
    "        comp_label = y_test[comp_idx]\n",
    "        \n",
    "        comp_analysis = explainer.analyze_sample(\n",
    "            spectrogram=comp_spec,\n",
    "            true_label=comp_label,\n",
    "            label_names=id_to_genre,\n",
    "            get_prediction=True\n",
    "        )\n",
    "        \n",
    "        comp_title = f\"Correct {id_to_genre[predictions[idx]]} - For Comparison\"\n",
    "        comp_save_path = misclass_path / f'compare_{i+1:02d}_correct_{comp_analysis[\"true_label_name\"]}.png'\n",
    "        \n",
    "        visualize_gradcam(\n",
    "            spectrogram=comp_spec,\n",
    "            heatmap=comp_analysis['heatmap'],\n",
    "            title=comp_title,\n",
    "            prediction=comp_analysis['predicted_label'],\n",
    "            true_label=comp_analysis['true_label_name'],\n",
    "            confidence=comp_analysis['confidence'],\n",
    "            save_path=str(comp_save_path),\n",
    "            show_plot=True\n",
    "        )\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\n✓ Section 2 complete! Visualizations saved to {misclass_path}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cba3e1",
   "metadata": {},
   "source": [
    "**Observations: Attention Patterns in Natural Failures**\n",
    "\n",
    "- **Partially similar attention patterns to the wrong class**: When the model misclassifies a sample, its attention sometimes focuses on regions similar to correctly classified samples of the predicted (wrong) genre, though not always as closely matched\n",
    "- **Genre confusion due to overlapping features**: Misclassifications occur when samples contain patterns characteristic of multiple genres, leading the model to focus on features that resemble a different genre\n",
    "- **Attention remains localized and confident**: Even in misclassifications, the model maintains focused attention on specific regions rather than showing uncertain patterns\n",
    "- **Varying similarity in decision strategies**: While some misclassified samples show attention patterns that closely match the predicted genre, others show less alignment, suggesting different types of confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5c8d77",
   "metadata": {},
   "source": [
    "## 8. Adversarial Failures - Attack Analysis\n",
    "\n",
    "Compare clean samples with their adversarial versions to understand how attacks shift model attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07774bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare adversarial attack framework\n",
    "art_classifier = prepare_classifier(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    input_shape=(1, 128, 130),\n",
    "    num_classes=10\n",
    ")\n",
    "\n",
    "print(\"ART classifier prepared for adversarial attacks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2592eacd",
   "metadata": {},
   "source": [
    "### 8.1: FGSM Attack Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04ee23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all 20 samples from Section 1 for FGSM attack\n",
    "attack_samples_fgsm = correct_samples[:20]\n",
    "epsilon = 0.1  # FGSM perturbation strength\n",
    "\n",
    "print(f\"Generating FGSM adversarial examples with epsilon={epsilon}...\")\n",
    "print(f\"Selected {len(attack_samples_fgsm)} samples for FGSM attack\\n\")\n",
    "\n",
    "# Prepare batch for attack\n",
    "X_clean_batch = X_test[attack_samples_fgsm]\n",
    "y_clean_batch = y_test[attack_samples_fgsm]\n",
    "\n",
    "# Generate FGSM adversarial examples\n",
    "X_fgsm_batch = generate_fgsm_attack(\n",
    "    classifier=art_classifier,\n",
    "    X=X_clean_batch,\n",
    "    y=y_clean_batch,\n",
    "    eps=epsilon\n",
    ")\n",
    "\n",
    "print(f\"✓ Generated {len(X_fgsm_batch)} FGSM adversarial examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e596ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate adversarial examples\n",
    "X_fgsm_tensor = torch.from_numpy(X_fgsm_batch).permute(0, 3, 1, 2).float().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits_fgsm = model(X_fgsm_tensor)\n",
    "    predictions_fgsm = torch.argmax(logits_fgsm, dim=1).cpu().numpy()\n",
    "    probabilities_fgsm = F.softmax(logits_fgsm, dim=1).cpu().numpy()\n",
    "\n",
    "# Compare clean vs adversarial predictions\n",
    "print(\"\\nFGSM Attack Results:\")\n",
    "print(\"=\" * 80)\n",
    "successful_attacks = 0\n",
    "\n",
    "for i, idx in enumerate(attack_samples_fgsm):\n",
    "    true_label = id_to_genre[y_clean_batch[i]]\n",
    "    pred_clean = id_to_genre[predictions[idx]]\n",
    "    pred_adv = id_to_genre[predictions_fgsm[i]]\n",
    "    conf_clean = probabilities[idx, predictions[idx]]\n",
    "    conf_adv = probabilities_fgsm[i, predictions_fgsm[i]]\n",
    "    \n",
    "    is_fooled = predictions[idx] != predictions_fgsm[i]\n",
    "    if is_fooled:\n",
    "        successful_attacks += 1\n",
    "    status = \"✗ FOOLED\" if is_fooled else \"✓ ROBUST\"\n",
    "    \n",
    "    print(f\"\\nSample {i+1} ({status}):\")\n",
    "    print(f\"  True label:  {true_label}\")\n",
    "    print(f\"  Clean pred:  {pred_clean} (conf: {conf_clean:.4f})\")\n",
    "    print(f\"  FGSM pred:   {pred_adv} (conf: {conf_adv:.4f})\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\nAttack success rate: {successful_attacks}/{len(attack_samples_fgsm)} ({successful_attacks/len(attack_samples_fgsm)*100:.1f}%)\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd083a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate side-by-side Grad-CAM comparisons for FGSM\n",
    "print(\"\\nGenerating FGSM Grad-CAM comparisons...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create subdirectory for FGSM attack analysis\n",
    "fgsm_path = FIGURES_PATH / 'gradcam' / 'adversarial_fgsm'\n",
    "fgsm_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i, idx in enumerate(attack_samples_fgsm):\n",
    "    print(f\"\\nProcessing FGSM comparison {i+1}/{len(attack_samples_fgsm)}...\")\n",
    "    \n",
    "    # Clean sample\n",
    "    clean_spec = X_test[idx]\n",
    "    clean_analysis = explainer.analyze_sample(\n",
    "        spectrogram=clean_spec,\n",
    "        true_label=y_test[idx],\n",
    "        label_names=id_to_genre,\n",
    "        get_prediction=True\n",
    "    )\n",
    "    \n",
    "    # Adversarial sample\n",
    "    adv_spec = X_fgsm_batch[i]\n",
    "    adv_analysis = explainer.analyze_sample(\n",
    "        spectrogram=adv_spec,\n",
    "        true_label=y_test[idx],\n",
    "        label_names=id_to_genre,\n",
    "        get_prediction=True\n",
    "    )\n",
    "    \n",
    "    # Create side-by-side comparison\n",
    "    title = f\"FGSM Attack Comparison - Sample {i+1}\"\n",
    "    save_path = fgsm_path / f'fgsm_{i+1:02d}_{clean_analysis[\"true_label_name\"]}.png'\n",
    "    \n",
    "    compare_gradcam_side_by_side(\n",
    "        spec1=clean_spec,\n",
    "        heatmap1=clean_analysis['heatmap'],\n",
    "        spec2=adv_spec,\n",
    "        heatmap2=adv_analysis['heatmap'],\n",
    "        title1=\"Clean\",\n",
    "        title2=\"FGSM (ε=0.1)\",\n",
    "        overall_title=title,\n",
    "        pred1=clean_analysis['predicted_label'],\n",
    "        pred2=adv_analysis['predicted_label'],\n",
    "        true_label=clean_analysis['true_label_name'],\n",
    "        conf1=clean_analysis['confidence'],\n",
    "        conf2=adv_analysis['confidence'],\n",
    "        save_path=str(save_path),\n",
    "        show_plot=True\n",
    "    )\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\n✓ FGSM comparisons complete! Visualizations saved to {fgsm_path}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ef8950",
   "metadata": {},
   "source": [
    "### 8.2: PGD Attack Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16f80a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same 20 samples for PGD attack (for direct comparison with FGSM)\n",
    "attack_samples_pgd = correct_samples[:20]\n",
    "epsilon_pgd = 0.1\n",
    "eps_step = 0.01\n",
    "max_iter = 40\n",
    "\n",
    "print(f\"Generating PGD adversarial examples...\")\n",
    "print(f\"Parameters: epsilon={epsilon_pgd}, eps_step={eps_step}, max_iter={max_iter}\")\n",
    "print(f\"Selected {len(attack_samples_pgd)} samples for PGD attack (same as FGSM)\\n\")\n",
    "\n",
    "# Prepare batch for attack\n",
    "X_clean_batch_pgd = X_test[attack_samples_pgd]\n",
    "y_clean_batch_pgd = y_test[attack_samples_pgd]\n",
    "\n",
    "# Generate PGD adversarial examples\n",
    "X_pgd_batch = generate_pgd_attack(\n",
    "    classifier=art_classifier,\n",
    "    X=X_clean_batch_pgd,\n",
    "    y=y_clean_batch_pgd,\n",
    "    eps=epsilon_pgd,\n",
    "    eps_step=eps_step,\n",
    "    max_iter=max_iter\n",
    ")\n",
    "\n",
    "print(f\"✓ Generated {len(X_pgd_batch)} PGD adversarial examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a50f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate PGD adversarial examples\n",
    "X_pgd_tensor = torch.from_numpy(X_pgd_batch).permute(0, 3, 1, 2).float().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits_pgd = model(X_pgd_tensor)\n",
    "    predictions_pgd = torch.argmax(logits_pgd, dim=1).cpu().numpy()\n",
    "    probabilities_pgd = F.softmax(logits_pgd, dim=1).cpu().numpy()\n",
    "\n",
    "# Compare clean vs adversarial predictions\n",
    "print(\"\\nPGD Attack Results:\")\n",
    "print(\"=\" * 80)\n",
    "successful_attacks_pgd = 0\n",
    "\n",
    "for i, idx in enumerate(attack_samples_pgd):\n",
    "    true_label = id_to_genre[y_clean_batch_pgd[i]]\n",
    "    pred_clean = id_to_genre[predictions[idx]]\n",
    "    pred_adv = id_to_genre[predictions_pgd[i]]\n",
    "    conf_clean = probabilities[idx, predictions[idx]]\n",
    "    conf_adv = probabilities_pgd[i, predictions_pgd[i]]\n",
    "    \n",
    "    is_fooled = predictions[idx] != predictions_pgd[i]\n",
    "    if is_fooled:\n",
    "        successful_attacks_pgd += 1\n",
    "    status = \"✗ FOOLED\" if is_fooled else \"✓ ROBUST\"\n",
    "    \n",
    "    print(f\"\\nSample {i+1} ({status}):\")\n",
    "    print(f\"  True label:  {true_label}\")\n",
    "    print(f\"  Clean pred:  {pred_clean} (conf: {conf_clean:.4f})\")\n",
    "    print(f\"  PGD pred:    {pred_adv} (conf: {conf_adv:.4f})\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\nAttack success rate: {successful_attacks_pgd}/{len(attack_samples_pgd)} ({successful_attacks_pgd/len(attack_samples_pgd)*100:.1f}%)\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a91bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate side-by-side Grad-CAM comparisons for PGD\n",
    "print(\"\\nGenerating PGD Grad-CAM comparisons...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create subdirectory for PGD attack analysis\n",
    "pgd_path = FIGURES_PATH / 'gradcam' / 'adversarial_pgd'\n",
    "pgd_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i, idx in enumerate(attack_samples_pgd):\n",
    "    print(f\"\\nProcessing PGD comparison {i+1}/{len(attack_samples_pgd)}...\")\n",
    "    \n",
    "    # Clean sample\n",
    "    clean_spec = X_test[idx]\n",
    "    clean_analysis = explainer.analyze_sample(\n",
    "        spectrogram=clean_spec,\n",
    "        true_label=y_test[idx],\n",
    "        label_names=id_to_genre,\n",
    "        get_prediction=True\n",
    "    )\n",
    "    \n",
    "    # Adversarial sample\n",
    "    adv_spec = X_pgd_batch[i]\n",
    "    adv_analysis = explainer.analyze_sample(\n",
    "        spectrogram=adv_spec,\n",
    "        true_label=y_test[idx],\n",
    "        label_names=id_to_genre,\n",
    "        get_prediction=True\n",
    "    )\n",
    "    \n",
    "    # Create side-by-side comparison\n",
    "    title = f\"PGD Attack Comparison - Sample {i+1}\"\n",
    "    save_path = pgd_path / f'pgd_{i+1:02d}_{clean_analysis[\"true_label_name\"]}.png'\n",
    "    \n",
    "    compare_gradcam_side_by_side(\n",
    "        spec1=clean_spec,\n",
    "        heatmap1=clean_analysis['heatmap'],\n",
    "        spec2=adv_spec,\n",
    "        heatmap2=adv_analysis['heatmap'],\n",
    "        title1=\"Clean\",\n",
    "        title2=f\"PGD (ε={epsilon_pgd}, iter={max_iter})\",\n",
    "        overall_title=title,\n",
    "        pred1=clean_analysis['predicted_label'],\n",
    "        pred2=adv_analysis['predicted_label'],\n",
    "        true_label=clean_analysis['true_label_name'],\n",
    "        conf1=clean_analysis['confidence'],\n",
    "        conf2=adv_analysis['confidence'],\n",
    "        save_path=str(save_path),\n",
    "        show_plot=True\n",
    "    )\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\n✓ PGD comparisons complete! Visualizations saved to {pgd_path}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6d4303",
   "metadata": {},
   "source": [
    "**Observations: Adversarial Attacks**\n",
    "\n",
    "- **Adversarial perturbations shift model attention**: Both FGSM and PGD attacks cause the model to focus on different regions of the spectrograms compared to clean samples\n",
    "- **PGD attacks cause stronger attention shifts than FGSM**: The iterative nature of PGD results in more dramatic changes in attention patterns, making it more effective at fooling the model\n",
    "- **Attention patterns in adversarial failures differ from natural failures**: While natural misclassifications show attention similar to the confused genre, adversarial attacks create artificial attention patterns that don't necessarily match any specific genre\n",
    "- **Some consistent confusion patterns across attack types**: For certain genres, both FGSM and PGD attacks lead to the same misclassification, though given the small sample size (20 samples), this observation is not strongly conclusive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca1cd8",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "**Grad-CAM Analysis Complete!**\n",
    "\n",
    "This notebook performed comprehensive explainability analysis.\n",
    "\n",
    "### Output Files\n",
    "All visualizations saved to: `results/figures/gradcam/`\n",
    "- `baseline_correct/` - Correct predictions analysis (20 samples - 2 per genre)\n",
    "- `natural_failures/` - Misclassification analysis with comparisons (10 samples: 5 misclassified + 5 correct for comparison)\n",
    "- `adversarial_fgsm/` - FGSM attack comparisons (20 samples)\n",
    "- `adversarial_pgd/` - PGD attack comparisons (20 samples)\n",
    "\n",
    "**Total: 70 visualizations organized by analysis type**\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "**1. Correct Predictions - Stable Genre-Specific Patterns**\n",
    "- The model has learned **distinct attention patterns for each genre**, focusing on specific frequency and time regions characteristic of each music style\n",
    "- **High consistency** between samples of the same genre demonstrates that the model relies on stable, discriminative features rather than random patterns\n",
    "- Attention is **localized and confident**, indicating the model has identified robust genre signatures in the spectrograms\n",
    "\n",
    "**2. Natural Failures - Feature Ambiguity and Genre Overlap**\n",
    "- Misclassifications occur when samples contain **overlapping features** from multiple genres, causing the model to focus on characteristics resembling the wrong genre\n",
    "- The model's attention patterns in misclassified samples show **varying degrees of similarity** to the predicted genre - some closely match while others are less aligned\n",
    "- Even when wrong, the model maintains **confident, focused attention**, suggesting it's not uncertain but rather genuinely confused by ambiguous spectral patterns\n",
    "- These failures represent **legitimate classification challenges** where genre boundaries are naturally blurred in the audio data\n",
    "\n",
    "**3. Adversarial Attacks - Artificial Manipulation of Decision Boundaries**\n",
    "- Both FGSM and PGD attacks successfully **shift model attention** to different regions, but through fundamentally different mechanisms than natural failures\n",
    "- Adversarial failures show **artificial attention patterns** that don't necessarily correspond to any specific genre's characteristics, unlike natural failures which align with confused genre features\n",
    "\n",
    "**Overall Conclusion**: The model demonstrates strong performance with consistent genre-specific attention strategies, but remains vulnerable to both natural genre ambiguity and adversarial perturbations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
